{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import seaborn as sns; sns.set()\n",
    "import csv\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "f = 0\n",
    "def get_csv_log(log_dirs):\n",
    "    steps, values = [], []\n",
    "    data = {}\n",
    "    # for idx, path in enumerate(log_dirs):\n",
    "    reader = csv.reader(open(log_dirs, 'r'))\n",
    "    \n",
    "    for row in reader:\n",
    "        wall_time, step, value = row\n",
    "        steps.append(step)\n",
    "        values.append(value)\n",
    "    steps.pop(0)\n",
    "    values.pop(0)\n",
    "    data[\"steps\"] = steps\n",
    "    data[\"values\"] = values\n",
    "    return data\n",
    "\n",
    "def get_tensorflow_log(log_dirs: list, label: str):\n",
    "    \"\"\"Returns log files for one label\"\"\"\n",
    "\n",
    "\n",
    "    # Loading too much data is slow...\n",
    "    tf_size_guidance = {\n",
    "        'compressedHistograms': 10,\n",
    "        'images': 0,\n",
    "        'scalars': 100,\n",
    "        'histograms': 1\n",
    "    }\n",
    "\n",
    "    steps, values = [], []\n",
    "    for idx, path in enumerate(log_dirs):\n",
    "        event_acc = EventAccumulator(path, tf_size_guidance)\n",
    "        event_acc.Reload()\n",
    "\n",
    "        # Show all tags in the log file\n",
    "        #print(event_acc.Tags())\n",
    "        assert label in event_acc.Tags()[\"scalars\"], \"Selected label: {} does not exist in the list of selectable labels:\\n {}\".format(label, event_acc.Tags()[\"scalars\"])\n",
    "\n",
    "        # get data by label\n",
    "        d =   event_acc.Scalars(label)\n",
    "        #data[label+\"_\"+str(idx)] = d\n",
    "        \n",
    "        for i in range(len(d)):\n",
    "            steps.append(d[i][1])\n",
    "            values.append(d[i][2])\n",
    "    data = {}\n",
    "\n",
    "    data[\"steps\"] = steps\n",
    "    data[\"values\"] = values\n",
    "    return data\n",
    "\n",
    "def create_dataset(data: dict, label:str):\n",
    "    d = {'Environment Steps': np.hstack(data[\"steps\"]), label :np.hstack(data[\"values\"])}\n",
    "    data = pd.DataFrame(data=d)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth(scalars , weight):  # Weight between 0 and 1\n",
    "    last = scalars[0]  # First value in the plot (first timestep)\n",
    "    smoothed = list()\n",
    "    for point in scalars:\n",
    "        smoothed_val = last * weight + (1 - weight) * point  # Calculate smoothed value\n",
    "        smoothed.append(smoothed_val)                        # Save it\n",
    "        last = smoothed_val                                  # Anchor the last smoothed value\n",
    "\n",
    "    return smoothed\n",
    "\n",
    "def rolling_window(a, window):\n",
    "    pad = np.ones(len(a.shape), dtype=np.int32)\n",
    "    pad[-1] = window-1\n",
    "    pad = list(zip(pad, np.zeros(len(a.shape), dtype=np.int32)))\n",
    "    a = np.pad(a, pad,mode='reflect')\n",
    "    shape = a.shape[:-1] + (a.shape[-1] - window + 1, window)\n",
    "    strides = a.strides + (a.strides[-1],)\n",
    "    return np.lib.stride_tricks.as_strided(a, shape=shape, strides=strides)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swap(data_sets, algorithm, i, j):\n",
    "    data_sets[i], data_sets[j] = data_sets[j], data_sets[i]\n",
    "    algorithm[0][i], algorithm[0][j] = algorithm[0][j], algorithm[0][i]\n",
    "    return data_sets,algorithm\n",
    "    \n",
    "def plot(data_sets, title, algorithm, label, dir,xlimit=31000):\n",
    "    # data_sets, algorithm = swap(data_sets,algorithm,1,2)\n",
    "    # data_sets, algorithm = swap(data_sets,algorithm,1,3)\n",
    "    # data_sets, algorithm = swap(data_sets,algorithm,1,2)\n",
    "\n",
    "\n",
    "    plot_i(data_sets, title, algorithm, label, dir,xlimit,8)\n",
    "    plot_i(data_sets, title, algorithm, label, dir,xlimit,15)\n",
    "    plt.show()\n",
    "    # time.sleep(3)\n",
    "    # plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_i(data_sets, title, algorithm, label, dir,xlimit,figs):\n",
    "    global f\n",
    "    f+=1\n",
    "    fig = plt.figure(f,figsize=(8,8))\n",
    "    # plt.clf()\n",
    "    # plt.subplot(111)\n",
    "    ax1 = plt.gca()\n",
    "    \n",
    "    plt.ticklabel_format(style='sci', axis='x',useOffset=False, scilimits=(0,0))\n",
    "    max_ = -100000\n",
    "    # colors =['crimson','lime','deepskyblue','magenta','darkviolet','darkorange','yellow','chocolate']\n",
    "    for idx, data in enumerate(data_sets):\n",
    "        plt.figure(f)\n",
    "        data=data.astype(float)\n",
    "        if xlimit!=None:\n",
    "            data = data.drop(data[data.values[...,0] > xlimit].index)\n",
    "        \n",
    "        smoothed = data.copy()\n",
    "        smoothed.values[...,1] = smooth(smoothed.values[...,1],0.9)\n",
    "        max_ = max(np.amax(data.values[...,1]),max_)\n",
    "\n",
    "        std = np.std(rolling_window(data.values[...,1], 30), axis=-1)\n",
    "\n",
    "\n",
    "        color = next(ax1._get_lines.prop_cycler)['color']\n",
    "        # color = colors[idx]\n",
    "        ax = data.plot(x='Environment Steps', y=label,alpha=0.3,color=color,label='',figsize=(figs, 8),ax = ax1)\n",
    "        smoothed.plot(x='Environment Steps', y=label,alpha=1.0,color=color,ax = ax1,label=algorithm[0][idx],linewidth=2.0)\n",
    "        \n",
    "        # color = next(ax1._get_lines.prop_cycler)['color']\n",
    "        plt.fill_between(data.values[...,0], smoothed.values[...,1]-std, smoothed.values[...,1]+std,color=color,alpha=0.1)\n",
    "        plt.fill_between(data.values[...,0], smoothed.values[...,1]-std, smoothed.values[...,1]+std,color=color,alpha=0.1)\n",
    "    \n",
    "    extratick = [max_]\n",
    "    plt.yticks(list(plt.yticks()[0])[1:-1]+extratick)\n",
    "    ax.set_ylabel(\"avg reward\")\n",
    "    if figs==8:\n",
    "        fsize=15\n",
    "    else:\n",
    "        fsize=15\n",
    "    plt.title(title, fontsize=fsize)\n",
    "    plt.xticks(fontsize=15)\n",
    "    plt.yticks(fontsize=15)\n",
    "    ax.yaxis.label.set_size(fsize)\n",
    "    ax.xaxis.label.set_size(fsize)\n",
    "\n",
    "    plt.legend(loc='lower right',fontsize=15)\n",
    "    plt.ylim(bottom=-200) \n",
    "    \n",
    "    if figs==8:\n",
    "        plt.savefig(dir+title+'_square.svg', format='svg')\n",
    "    else:\n",
    "        plt.savefig(dir+title+'.svg', format='svg')\n",
    "    # plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(l, n):\n",
    "    out = []\n",
    "    for i in range(0, len(l), n):\n",
    "        out.append(l[i:i+n])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fig(algorithm,logdir,title,labels,savedir,xlim=100000000):\n",
    "    print(logdir)\n",
    "    num_alg = len(algorithm)\n",
    "    subdirs = sorted(os.listdir(logdir))\n",
    "    subdirs_filtered = [d for d in subdirs if \".csv\" in d]\n",
    "    dirs = [logdir+d for d in subdirs_filtered]\n",
    "    print(dirs)\n",
    "\n",
    "    # dirs = [dirs]\n",
    "    # if num_alg > 1 and len(dirs) != 2:\n",
    "    #     #print(num_alg)\n",
    "    #     dirs = chunks(dirs, n= int(len(dirs)/num_alg))\n",
    "    #     #print(dirs)\n",
    "    # elif num_alg > 1 and len(algorithm[0]) == 2 and len(dirs) == 2:\n",
    "    #     dirs = [[dirs[0]],[dirs[1]]]\n",
    "\n",
    "\n",
    "    for i in range(len(label)):\n",
    "        print(\"Process Label: \", label[i])\n",
    "        data_per_label = []\n",
    "        for j in range(num_alg):\n",
    "            # data_log = get_tensorflow_log(log_dirs=dirs[j], label=label[0][i])\n",
    "            data_log2 = get_csv_log(dirs[j])\n",
    "            # dataset = create_dataset(data_log, label[i])\n",
    "            dataset2 = create_dataset(data_log2, label[i])\n",
    "            # data_per_label.append(dataset)\n",
    "            data_per_label.append(dataset2)\n",
    "        \n",
    "        plot(data_per_label, title[i], algorithm, label[i], savedir,xlimit=xlim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv_runs/LunarLander_Baseline_PRE_ERE/\n",
      "['csv_runs/LunarLander_Baseline_PRE_ERE/baseline.csv', 'csv_runs/LunarLander_Baseline_PRE_ERE/pre.csv', 'csv_runs/LunarLander_Baseline_PRE_ERE/pre_ere.csv']\n",
      "Process Label:  L\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-882afb0c82b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcreate_fig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"BASELINE PRE ERE\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"csv_runs/LunarLander_Baseline_PRE_ERE/\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"avg_reward/test\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"LunarLanderContinuous\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"plots/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-19-bbe2c9d89b41>\u001b[0m in \u001b[0;36mcreate_fig\u001b[0;34m(algorithm, logdir, title, label, savedir, xlim)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_alg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;31m# data_log = get_tensorflow_log(log_dirs=dirs[j], label=label[0][i])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mdata_log2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_csv_log\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m             \u001b[0;31m# dataset = create_dataset(data_log, label[i])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mdataset2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_log2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "create_fig(\"BASELINE PRE ERE\",\"csv_runs/LunarLander_Baseline_PRE_ERE/\",[avg_reward/test],\"LunarLanderContinuous\", \"plots/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ex2-imitation-learning] *",
   "language": "python",
   "name": "conda-env-ex2-imitation-learning-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
